{"cells":[{"cell_type":"markdown","metadata":{"id":"t2rd2GYlnYGX"},"source":["# 한국어 혐오 발언 탐지"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20790,"status":"ok","timestamp":1693462464751,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"b4YkgbEocsAb","outputId":"d150072e-7b5c-4acd-a6db-6646ed24b2c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ZaCnbT5Reaqf"},"source":["## 필요 라이브러리 설치"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70293,"status":"ok","timestamp":1693473244783,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"680tRbdhebLg","outputId":"fd3d8939-98c9-4846-ea74-7e599c3dde87"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.4)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.2)\n","Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.3)\n","Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.2.1)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.1)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.4.2)\n","Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n","Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n","Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install torchmetrics\n","!pip install accelerate -U\n","!pip install scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"Qz98cJCasPgI"},"source":["## 데이터셋 로드"]},{"cell_type":"markdown","metadata":{"id":"qqO0w2cKsjN1"},"source":["- 학습, 검증, 테스트 데이터셋 준비\n","- 라벨 정보\n","\n","      class_label:\n","        names:\n","          0: origin\n","          1: physical\n","          2: politics\n","          3: profanity\n","          4: age\n","          5: gender\n","          6: race\n","          7: religion\n","          8: not_hate_speech"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"-IczFOCZZfvx","outputId":"8318274e-bf48-48df-eb13-d661c1d6b94d"},"outputs":[],"source":["from datasets import load_dataset\n","\n","train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n","validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n","test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1853,"status":"ok","timestamp":1693473259520,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"wqHX7ImG54T6","outputId":"b927813c-2149-4d8c-d80d-df30f9049ac2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 78977\n","})\n","Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 8776\n","})\n","Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 21939\n","})\n","\"자한당틀딱들.. 악플질 고만해라.\"\n","[2, 4]\n"]}],"source":["# 데이터 예제 출력\n","\n","print(train)\n","print(validation)\n","print(test)\n","print(train['text'][0])\n","print(train['label'][0])"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693473259520,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"eo9Y7N2CsXC6","outputId":"5173db4e-a0d2-4a99-c38a-9dd786893b2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['\"자한당틀딱들.. 악플질 고만해라.\"', '정치적으로 편향된 평론한은 분은 별로...', '적당히좀 쳐먹지.그랬냐??? 안그래도 문재인 때문에 나라 엉망진창인데...', '\"안서는 아재들 풀발기 ㅋㄲㅋ\"', '우와 ㅋ 능력자', '맛녀석 콩트보다 약했음맛녀석 애청자로써 70%실력발휘', '주영훈 솔직히 호감임 잉꼬부부로 소문났잖아', '이게주간아이돌이랑머가달라...', '아오 슈박 회사생활도 졑깥고 돈벌기 힘들어 죽겠구만 뭔 저딴것들 자꾸 tv나와서 사람 짜증나게하냐 외국서 편히살려면 아닥하고 살아라 대한민국서 취미로 돈벌어가지말고 좀 끄지라고!', '\"문재인 하는게 뭐 별거있냐?ㅂㅅㅅㅋ가 하는짓인데 어련하겠어.ㅋㅋㅋ\"']\n","{'text': ['\"자한당틀딱들.. 악플질 고만해라.\"', '정치적으로 편향된 평론한은 분은 별로...', '적당히좀 쳐먹지.그랬냐??? 안그래도 문재인 때문에 나라 엉망진창인데...', '\"안서는 아재들 풀발기 ㅋㄲㅋ\"', '우와 ㅋ 능력자', '맛녀석 콩트보다 약했음맛녀석 애청자로써 70%실력발휘', '주영훈 솔직히 호감임 잉꼬부부로 소문났잖아', '이게주간아이돌이랑머가달라...', '아오 슈박 회사생활도 졑깥고 돈벌기 힘들어 죽겠구만 뭔 저딴것들 자꾸 tv나와서 사람 짜증나게하냐 외국서 편히살려면 아닥하고 살아라 대한민국서 취미로 돈벌어가지말고 좀 끄지라고!', '\"문재인 하는게 뭐 별거있냐?ㅂㅅㅅㅋ가 하는짓인데 어련하겠어.ㅋㅋㅋ\"'], 'label': [[2, 4], [8], [2], [4], [8], [8], [8], [8], [3], [2, 3]]}\n"]}],"source":["# 사전\n","print(train['text'][0:10])\n","\n","# 리스트\n","print(train[0:10])\n"]},{"cell_type":"markdown","metadata":{"id":"R_2uWy1p8Ifx"},"source":["## 모델 및 토크나이저 로드"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"elapsed":5145,"status":"error","timestamp":1693917591046,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"jnbQNuzk7rZR","outputId":"f19e3aee-c3c4-482b-b33b-27332c27cd11"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): GELUActivation()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=9, bias=True)\n","  )\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","name_cards= ['monologg/koelectra-base-v3-discriminator', 'kobert-base-v1', 'bert-base-multilingual-cased']\n","name_card = \"monologg/koelectra-base-v3-discriminator\"\n","num_labels = 9\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(name_card, do_lower_case=False)\n","model = AutoModelForSequenceClassification.from_pretrained(name_card, num_labels=num_labels, problem_type=\"multi_label_classification\")\n","model.to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jTUT0OSy5mm-","outputId":"e7ba0517-c6a4-4343-e995-f6ff01914639"},"outputs":[{"data":{"text/plain":["Model(\n","  (model): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n","  (n_classifier): Linear(in_features=768, out_features=9, bias=True)\n","  (intent_loss): FocalLoss()\n","  (n_loss): CrossEntropyLoss()\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import torch.nn as nn\n","from transformers import AutoModel\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=1, gamma=1):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n","        pt = torch.exp(-BCE_loss)\n","        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n","        return F_loss.mean()\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.model = AutoModel.from_pretrained(name_card)\n","\n","        self.classifier = nn.Linear(self.model.config.hidden_size, num_labels)\n","        self.n_classifier = nn.Linear(self.model.config.hidden_size, num_labels)\n","\n","        # self.intent_loss = nn.BCEWithLogitsLoss()\n","        self.intent_loss = FocalLoss()\n","        self.n_loss = nn.CrossEntropyLoss()\n","\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None, n_label=None):\n","        model_input= {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","        }\n","\n","        if token_type_ids is not None:\n","            model_input['token_type_ids'] = token_type_ids\n","\n","        hidden = self.model(**model_input)\n","\n","        # some output dont have pooler_output\n","        if hasattr(hidden, 'pooler_output'):\n","            cls = hidden.pooler_output\n","        else:\n","            cls = hidden.last_hidden_state[:, 0, :]\n","\n","        hidden = hidden.last_hidden_state[:, 1:, :]\n","\n","        intent_logit = self.classifier(hidden.mean(dim=1))\n","        n_logit = self.n_classifier(cls)\n","\n","        intent_loss = self.intent_loss(intent_logit, labels)\n","        num_loss = self.n_loss(n_logit, n_label)\n","\n","        loss = intent_loss + num_loss\n","\n","        model_output = {\n","            'loss': loss,\n","            'intent_logit': intent_logit,\n","            'n_logit': n_logit,\n","        }\n","\n","        return model_output\n","\n","\n","model = Model()\n","model.to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":802,"status":"ok","timestamp":1693464855626,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"67p9XNOm-K12","outputId":"713fe8a9-7638-403f-86bf-f7920399f60d"},"outputs":[{"name":"stdout","output_type":"stream","text":["['[CLS]', '\"', '자', '##한', '##당', '##틀', '##딱', '##들', '.', '.', '악', '##플', '##질', '고만', '##해', '##라', '.', '\"', '[SEP]']\n","[2, 6, 3254, 4283, 4403, 4882, 5136, 4006, 18, 18, 3080, 4711, 4152, 25141, 4151, 4118, 18, 6, 3]\n","{'input_ids': [2, 6, 3254, 4283, 4403, 4882, 5136, 4006, 18, 18, 3080, 4711, 4152, 25141, 4151, 4118, 18, 6, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["# 토크나이저 예시\n","\n","ids = tokenizer.encode(train['text'][0])\n","tokenized_words = tokenizer.convert_ids_to_tokens(ids)\n","model_input = tokenizer(train['text'][0])\n","\n","print(tokenized_words)\n","print(ids)\n","print(model_input)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":501,"status":"ok","timestamp":1693465554951,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"ig5R7bPUw8br","outputId":"0c8e4d33-c42f-47fe-814b-55bb8a96115f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [2, 6, 3254, 3], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}\n","['[CLS]', '\"', '자', '[SEP]']\n"]}],"source":["# 토크나이저 예시2\n","\n","model_input = tokenizer(train['text'][0], max_length=4, truncation=True, padding=\"max_length\")\n","print(model_input)\n","reverse = tokenizer.convert_ids_to_tokens(model_input['input_ids'])\n","print(reverse)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1298,"status":"ok","timestamp":1693465557105,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"PN25M6wXxhus","outputId":"1d5b61c5-3fdb-4010-8a5b-42595cf9db93"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [2, 6, 3254, 3], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}\n"]},{"name":"stdout","output_type":"stream","text":["{'input_ids': [0, 113, 43998, 2], 'attention_mask': [1, 1, 1, 1]}\n","{'input_ids': [101, 1000, 100, 102], 'attention_mask': [1, 1, 1, 1]}\n"]}],"source":["# 토크나이저 예시3\n","\n","print(model_input)\n","\n","another_name_card = 'roberta-base'\n","another_tokenizer = AutoTokenizer.from_pretrained(another_name_card, do_lower_case=False)\n","model_input = another_tokenizer(train['text'][0], max_length=4, truncation=True, padding=\"max_length\")\n","print(model_input)\n","\n","another_name_card = 'distilbert-base-uncased'\n","another_tokenizer = AutoTokenizer.from_pretrained(another_name_card, do_lower_case=False)\n","model_input = another_tokenizer(train['text'][0], max_length=4, truncation=True, padding=\"max_length\")\n","print(model_input)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5m9abTda-TIX"},"outputs":[],"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","\n","def tokenize_function(examples):\n","    model_input = tokenizer(examples['text'], max_length=128, truncation=True, padding=\"max_length\")\n","\n","    mlb = MultiLabelBinarizer(classes=[0,1,2,3,4,5,6,7,8])\n","    one_hot_labels = mlb.fit_transform(examples['label'])\n","\n","    model_input['label'] = one_hot_labels\n","    # model_input['n_label'] = []\n","    # for one_hot_label in one_hot_labels:\n","    #     if one_hot_label[-1] == 0:\n","    #         model_input['n_label'].append(sum(one_hot_label) - 1)\n","    #     else:\n","    #         model_input['n_label'].append(0)\n","    model_input['n_label'] = [sum(one_hot_label[:-1]) for one_hot_label in one_hot_labels] # 이거도 가능할 듯\n","    # model_input['n_label'] = [sum(one_hot_label) - 1 for one_hot_label in one_hot_labels]\n","\n","    return model_input"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195,"referenced_widgets":["0912b330f7354f9f95c60a87f8caf994","8a4e9fa141b34dddba9ce934bfb3133d","ebe85e2f525747c2bab1059d40917cf6","57342a2d55b74c3b9a69a1805f94889c","5097178ceeaa4bfca166641758ad2fc4","6cf048b7a36a47c7a23f8eab7397d481","538a4c1eed7e40d29234c7120a3761b6","c92d88c8388541e29bedf12c03bc9bd7","a537a5456f44480b8e94dad15ea64b11","b26ac6c874384214a6e05402e16216af","cedd6f11236a49518a88510e7a81bd56"]},"executionInfo":{"elapsed":28200,"status":"ok","timestamp":1693473289678,"user":{"displayName":"조성민","userId":"07022805073498996704"},"user_tz":-540},"id":"OjnfLtIVIrIW","outputId":"7de4c6a9-bf5a-4e20-f345-89653d5262ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 78977\n","})\n","Dataset({\n","    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'n_label'],\n","    num_rows: 78977\n","})\n"]}],"source":["print(train)\n","\n","tokenized_train = train.map(tokenize_function, batched=True)\n","tokenized_valid = validation.map(tokenize_function, batched=True)\n","\n","print(tokenized_train)"]},{"cell_type":"markdown","metadata":{"id":"61-IoYan9kAq"},"source":["## 모델 학습"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-WqZr7Mz7rXD"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","BATCH_SIZE = 64 # 32\n","EPOCHS = 1\n","\n","save_dir = '/root/korean_hate_speech_detection/model'\n","\n","training_args = TrainingArguments(\n","    output_dir=save_dir,\n","    do_train=True,\n","    do_eval=True,\n","    # save_steps=999999999,\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    logging_strategy=\"epoch\",\n","    logging_dir='./logs',\n","    learning_rate=2e-5,\n","    run_name=\"v1\",\n","    save_strategy=\"no\",\n","    label_names=['labels', 'n_label'],\n","    seed=42,\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"lRE8aPEzQPrL"},"outputs":[],"source":["import torch\n","from torchmetrics import Accuracy, F1Score, HammingDistance, AUROC, ExactMatch\n","\n","def compute_metrics(eval_pred):\n","    threshold = 0.5\n","\n","    # model_output = eval_pred.predictions\n","    # labels = eval_pred.label_ids\n","    intent_logits, n_logits = eval_pred.predictions\n","    intent_labels, n_labels = eval_pred.label_ids\n","\n","\n","    intent_logits = torch.Tensor(intent_logits)\n","    intent_labels = torch.Tensor(intent_labels).long()\n","\n","    n_logits = torch.Tensor(n_logits)\n","    n_labels = torch.Tensor(n_labels).long()\n","\n","    n_pred = torch.argmax(n_logits, dim=1)\n","\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(intent_logits))\n","\n","    preds = torch.zeros(size = probs.size())\n","    preds[probs >= threshold] = 1\n","\n","    ...\n","\n","    for b in range(preds.shape[0]):\n","\n","        # hate: 1, no_hate: 1\n","        if preds[b][8] == 1:\n","            preds[b][:-1] = 0\n","\n","        # hate: 0, no_hate: 0\n","        if preds[b][:-1].sum() == 0:\n","            preds[b][8] = 1\n","\n","        # hate: 1, no_hate: 1\n","        if preds[b][:-1].sum() != 0:\n","            preds[b][8] = 0\n","\n","\n","\n","    accuracy = Accuracy(task='multilabel', num_labels=9)\n","    f1_macro = F1Score(task=\"multilabel\", num_labels=9, average='macro')\n","    f1_micro = F1Score(task=\"multilabel\", num_labels=9, average='micro')\n","    f1_weight = F1Score(task=\"multilabel\", num_labels=9, average='weighted')\n","    em = ExactMatch(task='multiclass', num_classes=2)\n","    auroc = AUROC(task='multilabel', num_labels=9, average='micro')\n","    hamming = HammingDistance(task=\"multiclass\", num_classes=2)\n","    n_int_accuracy = Accuracy(task='multiclass', num_classes=9)\n","\n","    f1s = F1Score(task='multilabel', num_labels=9, average=None)\n","\n","    print(\"f1s\")\n","    print(f1s(preds, intent_labels))\n","\n","\n","    metrics = {'accuracy': accuracy(preds, intent_labels),\n","               'f1_macro': f1_macro(preds, intent_labels),\n","               'f1_micro': f1_micro(preds, intent_labels),\n","               'f1_weighted': f1_weight(preds, intent_labels),\n","               'auroc': auroc(preds, intent_labels),\n","               'hamming_loss': hamming(preds, intent_labels),\n","               'em': em(preds, intent_labels),\n","               'n_int_accuracy': n_int_accuracy(n_pred, n_labels)}\n","    return metrics"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"hbxV9-G6FDM5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_valid,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"qJbkJX5wCjMA"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1235' max='1235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1235/1235 06:38, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Auroc</th>\n","      <th>Hamming Loss</th>\n","      <th>Em</th>\n","      <th>N Int Accuracy</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","      <th>Steps Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.735400</td>\n","      <td>0.609073</td>\n","      <td>0.902917</td>\n","      <td>0.150252</td>\n","      <td>0.590034</td>\n","      <td>0.452693</td>\n","      <td>0.754375</td>\n","      <td>0.097083</td>\n","      <td>0.582612</td>\n","      <td>0.799225</td>\n","      <td>16.157400</td>\n","      <td>543.157000</td>\n","      <td>8.541000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["f1s\n","tensor([0.0000, 0.0000, 0.0089, 0.5784, 0.0000, 0.0000, 0.0000, 0.0000, 0.7649])\n"]},{"data":{"text/plain":["TrainOutput(global_step=1235, training_loss=0.7354170455623735, metrics={'train_runtime': 399.713, 'train_samples_per_second': 197.584, 'train_steps_per_second': 3.09, 'total_flos': 0.0, 'train_loss': 0.7354170455623735, 'epoch': 1.0})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"d2isIEV05mnB"},"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"5zQeEYdxzKDP"},"outputs":[],"source":["# trainer.save_model()\n","import os\n","torch.save(model.state_dict(), os.path.join(f\"{save_dir}\", \"model.pt\"))"]},{"cell_type":"markdown","metadata":{"id":"dr6FMPTmeXKt"},"source":["## 예측"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"6mMdVLTm7rUx","outputId":"e22b7a53-6266-48d9-f725-89b2bc0ac6b6"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14d8a8f01dd347d38a9c6ecb8820fe8b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/21939 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Model(\n","  (model): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n","  (n_classifier): Linear(in_features=768, out_features=9, bias=True)\n","  (intent_loss): FocalLoss()\n","  (n_loss): CrossEntropyLoss()\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_test = test.map(tokenize_function, batched=True)\n","\n","state_dict = torch.load(f\"{save_dir}/model.pt\")\n","\n","model = Model()\n","model.load_state_dict(state_dict=state_dict)\n","model.to(device)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"B6ekYwMLooHm"},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_test,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"u4SFg8R3otvF","outputId":"d9372bfa-ccd1-424b-b0ab-e25d74bb7252"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  2/343 00:00 < 00:39, 8.72 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["f1s\n","tensor([0.0000, 0.0000, 0.0073, 0.5944, 0.0000, 0.0000, 0.0000, 0.0000, 0.7523])\n"]},{"data":{"text/plain":["{'eval_loss': 0.616534411907196,\n"," 'eval_accuracy': 0.8985520601272583,\n"," 'eval_f1_macro': 0.15044835209846497,\n"," 'eval_f1_micro': 0.5735998749732971,\n"," 'eval_f1_weighted': 0.43247219920158386,\n"," 'eval_auroc': 0.7445394396781921,\n"," 'eval_hamming_loss': 0.1014479398727417,\n"," 'eval_em': 0.5630612373352051,\n"," 'eval_n_int_accuracy': 0.7946578860282898,\n"," 'eval_runtime': 40.3297,\n"," 'eval_samples_per_second': 543.991,\n"," 'eval_steps_per_second': 8.505}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["Qz98cJCasPgI"],"provenance":[{"file_id":"171KhS1_LVBtpAFd_kaT8lcrZmhcz5ehY","timestamp":1693358862334},{"file_id":"1_yQBkQObI4NWjCw7fzw-0PiXmJT1YUoy","timestamp":1669644928935}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0912b330f7354f9f95c60a87f8caf994":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a4e9fa141b34dddba9ce934bfb3133d","IPY_MODEL_ebe85e2f525747c2bab1059d40917cf6","IPY_MODEL_57342a2d55b74c3b9a69a1805f94889c"],"layout":"IPY_MODEL_5097178ceeaa4bfca166641758ad2fc4"}},"5097178ceeaa4bfca166641758ad2fc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538a4c1eed7e40d29234c7120a3761b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57342a2d55b74c3b9a69a1805f94889c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b26ac6c874384214a6e05402e16216af","placeholder":"​","style":"IPY_MODEL_cedd6f11236a49518a88510e7a81bd56","value":" 78977/78977 [00:27&lt;00:00, 3047.45 examples/s]"}},"6cf048b7a36a47c7a23f8eab7397d481":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a4e9fa141b34dddba9ce934bfb3133d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cf048b7a36a47c7a23f8eab7397d481","placeholder":"​","style":"IPY_MODEL_538a4c1eed7e40d29234c7120a3761b6","value":"Map: 100%"}},"a537a5456f44480b8e94dad15ea64b11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b26ac6c874384214a6e05402e16216af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c92d88c8388541e29bedf12c03bc9bd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cedd6f11236a49518a88510e7a81bd56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebe85e2f525747c2bab1059d40917cf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c92d88c8388541e29bedf12c03bc9bd7","max":78977,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a537a5456f44480b8e94dad15ea64b11","value":78977}}}}},"nbformat":4,"nbformat_minor":0}
